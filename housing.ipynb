{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "# %tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "\n",
    "#  (tf.python.data)\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "# tf.logging.ERROR and tf.logging.set_verbosity is deprecated\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.compat.v1.logging.ERROR\n",
    "tf.compat.v1.logging.set_verbosity\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\ncount    17000.0   17000.0             17000.0      17000.0         17000.0   \nmean      -119.6      35.6                28.6       2643.7           539.4   \nstd          2.0       2.1                12.6       2179.9           421.5   \nmin       -124.3      32.5                 1.0          2.0             1.0   \n25%       -121.8      33.9                18.0       1462.0           297.0   \n50%       -118.5      34.2                29.0       2127.0           434.0   \n75%       -118.0      37.7                37.0       3151.2           648.2   \nmax       -114.3      42.0                52.0      37937.0          6445.0   \n\n       population  households  median_income  median_house_value  \ncount     17000.0     17000.0        17000.0             17000.0  \nmean       1429.6       501.2            3.9               207.3  \nstd        1147.9       384.5            1.9               116.0  \nmin           3.0         1.0            0.5                15.0  \n25%         790.0       282.0            2.6               119.4  \n50%        1167.0       409.0            3.5               180.4  \n75%        1721.0       605.2            4.8               265.0  \nmax       35682.0      6082.0           15.0               500.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>17000.0</td>\n      <td>17000.0</td>\n      <td>17000.0</td>\n      <td>17000.0</td>\n      <td>17000.0</td>\n      <td>17000.0</td>\n      <td>17000.0</td>\n      <td>17000.0</td>\n      <td>17000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-119.6</td>\n      <td>35.6</td>\n      <td>28.6</td>\n      <td>2643.7</td>\n      <td>539.4</td>\n      <td>1429.6</td>\n      <td>501.2</td>\n      <td>3.9</td>\n      <td>207.3</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.0</td>\n      <td>2.1</td>\n      <td>12.6</td>\n      <td>2179.9</td>\n      <td>421.5</td>\n      <td>1147.9</td>\n      <td>384.5</td>\n      <td>1.9</td>\n      <td>116.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-124.3</td>\n      <td>32.5</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-121.8</td>\n      <td>33.9</td>\n      <td>18.0</td>\n      <td>1462.0</td>\n      <td>297.0</td>\n      <td>790.0</td>\n      <td>282.0</td>\n      <td>2.6</td>\n      <td>119.4</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-118.5</td>\n      <td>34.2</td>\n      <td>29.0</td>\n      <td>2127.0</td>\n      <td>434.0</td>\n      <td>1167.0</td>\n      <td>409.0</td>\n      <td>3.5</td>\n      <td>180.4</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>-118.0</td>\n      <td>37.7</td>\n      <td>37.0</td>\n      <td>3151.2</td>\n      <td>648.2</td>\n      <td>1721.0</td>\n      <td>605.2</td>\n      <td>4.8</td>\n      <td>265.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>-114.3</td>\n      <td>42.0</td>\n      <td>52.0</td>\n      <td>37937.0</td>\n      <td>6445.0</td>\n      <td>35682.0</td>\n      <td>6082.0</td>\n      <td>15.0</td>\n      <td>500.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Load dataset\n",
    "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
    "\n",
    "'''  Randomize the data, just to be sure not to get any pathological ordering effects that might harm the performance of Stochastic Gradient Descent. Additionally, we'll scale median_house_value to be in units of thousands, so it can be learned a little more easily with learning rates in a range that we usually use. '''\n",
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index)\n",
    ")\n",
    "california_housing_dataframe[\"median_house_value\"] /= 1000.0\n",
    "california_housing_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Step 1: Define Features and Configure Feature Columns\n",
    "In order to import our training data into TensorFlow, we need to specify what type of data each feature contains. There are two main types of data we'll use in this and future exercises:\n",
    "Categorical Data: Data that is textual. In this exercise, our housing data set does not contain any categorical features, but examples you might see would be the home style, the words in a real-estate ad.\n",
    "Numerical Data: Data that is a number (integer or float) and that you want to treat as a number. As we will discuss more later sometimes you might want to treat numerical data (e.g., a postal code) as if it were categorical.\n",
    "In TensorFlow, we indicate a feature's data type using a construct called a feature column. Feature columns store only a description of the feature data; they do not contain the feature data itself.\n",
    "To start, we're going to use just one numeric input feature, total_rooms. The following code pulls the total_rooms data from our california_housing_dataframe and defines the feature column using numeric_column, which specifies its data is numeric: '''\n",
    "\n",
    "# Define the input feature total_rooms\n",
    "my_feature = california_housing_dataframe[[\"total_rooms\"]]\n",
    "\n",
    "# Configure a numeric feature column for total_rooms.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"total_rooms\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Step 2: Define the Target\n",
    "Next, we'll define our target, which is median_house_value. Again, we can pull it from our california_housing_dataframe: \n",
    "'''\n",
    "# Define the label\n",
    "targets = california_housing_dataframe[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\nINFO:tensorflow:Using default config.\nWARNING:tensorflow:Using temporary folder as model directory: /var/folders/_7/st0pp8t16gddgttv25kb4rd80000gn/T/tmpre6wfbyy\nINFO:tensorflow:Using config: {'_model_dir': '/var/folders/_7/st0pp8t16gddgttv25kb4rd80000gn/T/tmpre6wfbyy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a3b6fb850>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
    }
   ],
   "source": [
    "''' Step 3: Configure the LinearRegressor\n",
    "Next, we'll configure a linear regression model using LinearRegressor. We'll train this model using the GradientDescentOptimizer, which implements Mini-Batch Stochastic Gradient Descent (SGD). The learning_rate argument controls the size of the gradient step.\n",
    "NOTE: To be safe, we also apply gradient clipping to our optimizer via clip_gradients_by_norm. Gradient clipping ensures the magnitude of the gradients do not become too large during training, which can cause gradient descent to fail. '''\n",
    "\n",
    "# Use gradient descent as the optimizer for training the model.\n",
    "my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
    "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "# Configure the linear regression model with our feature columns and optimizer.\n",
    "# Set a learning rate of 0.0000001 for Gradient Descent.\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    optimizer=my_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Step 4: Define the Input Function\n",
    "To import our California housing data into our LinearRegressor, we need to define an input function, which instructs TensorFlow how to preprocess the data, as well as how to batch, shuffle, and repeat it during model training.\n",
    "First, we'll convert our pandas feature data into a dict of NumPy arrays. We can then use the TensorFlow Dataset API to construct a dataset object from our data, and then break our data into batches of batch_size, to be repeated for the specified number of epochs (num_epochs).\n",
    "NOTE: When the default value of num_epochs=None is passed to repeat(), the input data will be repeated indefinitely.\n",
    "Next, if shuffle is set to True, we'll shuffle the data so that it's passed to the model randomly during training. The buffer_size argument specifies the size of the dataset from which shuffle will randomly sample.\n",
    "Finally, our input function constructs an iterator for the dataset and returns the next batch of data to the LinearRegressor. '''\n",
    "\n",
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "\n",
    "    \"\"\" Trains a linear regression model of one feature.\n",
    "    Args:\n",
    "        features: pandas DataFrame of features\n",
    "        targets: pandas DataFrame of targets\n",
    "        batch_size: Size of batches to be passed to the model\n",
    "        shuffle: True or False. Whether to shuffle the data.\n",
    "        num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
    "    Returns:\n",
    "        Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}\n",
    "\n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "\n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=10000)\n",
    "\n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/lorenzor.bartolo/miniconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\nWARNING:tensorflow:From <ipython-input-8-eaeec0c96b4b>:32: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\nINFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:From /Users/lorenzor.bartolo/miniconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:305: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `layer.add_weight` method instead.\nWARNING:tensorflow:From /Users/lorenzor.bartolo/miniconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /Users/lorenzor.bartolo/miniconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /Users/lorenzor.bartolo/miniconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Saving checkpoints for 0 into /var/folders/_7/st0pp8t16gddgttv25kb4rd80000gn/T/tmpre6wfbyy/model.ckpt.\nINFO:tensorflow:loss = 63001.0, step = 1\nINFO:tensorflow:Saving checkpoints for 100 into /var/folders/_7/st0pp8t16gddgttv25kb4rd80000gn/T/tmpre6wfbyy/model.ckpt.\nINFO:tensorflow:Loss for final step: 15961.449.\n"
    }
   ],
   "source": [
    "''' Step 5: Train the Model\n",
    "\n",
    "We can now call train() on our linear_regressor to train the model. We'll wrap my_input_fn in a lambda so we can pass in my_feature and targets as arguments (see this TensorFlow input function tutorial for more details), and to start, we'll train for 100 steps. '''\n",
    "\n",
    "_ = linear_regressor.train(\n",
    "    input_fn = lambda:my_input_fn(my_feature, targets),\n",
    "    steps=100\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitmyenvcondae551758100324a67b637706725420e9f",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}